{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hackerearth Deep learning competition : Detect emotions of your favorite toons (Tom and Jerry) !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Frames generation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "videoFile = \"video.mp4\"\n",
    "import math\n",
    "cap = cv2.VideoCapture(videoFile)\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename = 'images/' +  str(int(x)) + \".jpg\";x+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Segmentation of Tom and Jerry faces \n",
    "Use code for both train frames and test frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "def facecrop(image,character):\n",
    "    \n",
    "    if character['name'] == \"Tom\":\n",
    "\n",
    "        img = cv2.imread(image)\n",
    "        cascade = cv2.CascadeClassifier(character['cascade'])\n",
    "        \n",
    "        faces = cascade.detectMultiScale(img,scaleFactor=1.10, \n",
    "                        minNeighbors=40, \n",
    "                        minSize=(24, 24),\n",
    "                        flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        \n",
    "        \n",
    "        for f in faces:\n",
    "            x, y, w, h = [ v for v in f ]\n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h), (255,255,255))\n",
    "\n",
    "            sub_face = img[y:y+h, x:x+w]\n",
    "            fname, ext = os.path.splitext(image)\n",
    "        \n",
    "            cv2.imwrite(fname+ext, sub_face)\n",
    "\n",
    "    elif character['name'] == \"Jerry\":\n",
    "\n",
    "        img = cv2.imread(image)\n",
    "        cascade = cv2.CascadeClassifier(character['cascade'])\n",
    "       \n",
    "        faces = cascade.detectMultiScale(img,scaleFactor=1.10, \n",
    "                        minNeighbors=20, \n",
    "                        minSize=(24, 24),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        \n",
    "        for f in faces:\n",
    "            x, y, w, h = [ v for v in f ]\n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h), (255,255,255))\n",
    "\n",
    "            sub_face = img[y:y+h, x:x+w]\n",
    "            fname, ext = os.path.splitext(image)\n",
    "            \n",
    "            cv2.imwrite(fname+ext, sub_face)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters1 = [\n",
    "    {\n",
    "        'name':      \"Tom\",\n",
    "        'cascade':   './haar_cascades/tom.xml'\n",
    "        \n",
    "    }\n",
    "]\n",
    "characters2 = [\n",
    "    {\n",
    "        'name':      \"Jerry\",\n",
    "        'cascade':   './haar_cascades/jerry.xml'\n",
    "    }\n",
    "]\n",
    "\n",
    "folder_path= '' #folder path\n",
    "for img in os.listdir(folder_path):\n",
    "    img = os.path.join(folder_path, img)\n",
    "    for ch in characters1:\n",
    "        facecrop(img,ch)\n",
    "for img in os.listdir(folder_path):\n",
    "    img = os.path.join(folder_path, img)\n",
    "    for ch in characters2:\n",
    "        facecrop(img,ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model development and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    " \n",
    "# define cnn model\n",
    "def define_model():\n",
    "    # load model\n",
    "    model = VGG16(include_top=False, input_shape=(60, 60, 3))\n",
    "    # mark loaded layers as not trainable\n",
    "    classes_num=5\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    # add new classifier layers\n",
    "    flat1 = Flatten()(model.layers[-1].output)\n",
    "    class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "    output = Dense(classes_num, activation='softmax')(class1)\n",
    "    # define new model\n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    " \n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "# define model\n",
    "    model = define_model()\n",
    "    # create data generator\n",
    "    datagen = ImageDataGenerator(featurewise_center=True)\n",
    "    # specify imagenet mean values for centering\n",
    "    datagen.mean = [123.68, 116.779, 103.939]\n",
    "    # prepare iterator\n",
    "    train_it = datagen.flow_from_directory('train_data_folder/',\n",
    "    class_mode='categorical', batch_size=32, target_size=(60, 60))\n",
    "    # fit model\n",
    "    model.fit_generator(train_it, steps_per_epoch=len(train_it), epochs=60, verbose=1)\n",
    "    # save model\n",
    "    model.save('result.h5')\n",
    " # entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Testing on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "folder_path = './test_data_folder/'  #after segmentation\n",
    "prediction=[]\n",
    "model = load_model('result.h5')\n",
    "# load and prepare the image\n",
    "def load_image(filename):\n",
    "    # load the image\n",
    "    img = load_img(filename, target_size=(60, 60))\n",
    "    # convert to array\n",
    "    img = img_to_array(img)\n",
    "    # reshape into a single sample with 3 channels\n",
    "    img = img.reshape(1, 60, 60, 3)\n",
    "    # center pixel data\n",
    "    img = img.astype('float32')\n",
    "    img = img - [123.68, 116.779, 103.939]\n",
    "    return img\n",
    " \n",
    "# load an image and predict the class\n",
    "def run_example():\n",
    "    # load the image\n",
    "    \n",
    "    for img in os.listdir(folder_path):\n",
    "    # load model\n",
    "#         print(img)\n",
    "        x=img\n",
    "        img = os.path.join(folder_path, img)\n",
    "        img = load_image(img)\n",
    "       \n",
    "    # predict the class\n",
    "        result = model.predict(img)\n",
    "        m=max(result[0])\n",
    "\n",
    "        itemindex = np.where(result[0]==m)\n",
    "\n",
    "        if(itemindex[0][0])==0:\n",
    "            prediction.append((x,'angry'))\n",
    "        elif(itemindex[0][0])==1:\n",
    "            prediction.append((x,'happy'))\n",
    "        elif(itemindex[0][0])==2:\n",
    "            prediction.append((x,'sad'))\n",
    "        elif(itemindex[0][0])==3:\n",
    "            prediction.append((x,'surprised'))\n",
    "        elif(itemindex[0][0])==4:\n",
    "            prediction.append((x,'Unknown'))\n",
    "            \n",
    "    \n",
    "# entry point, run the example\n",
    "run_example()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get results as per expected format\n",
    "def Sort_Tuple(tup):  \n",
    "    \n",
    "    tup.sort(key = lambda x: (int(x[0].split('.')[0]), x[0]))  \n",
    "    return tup \n",
    "l=Sort_Tuple(prediction)\n",
    "res=[]\n",
    "for i in l:\n",
    "    res.append(i[1])\n",
    "# print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Make results.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('Test.csv')\n",
    "data['Emotion'] = res\n",
    "data.to_csv('results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
